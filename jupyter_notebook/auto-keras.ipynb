{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Origin  \n",
       "393          82       1  \n",
       "394          82       2  \n",
       "395          82       1  \n",
       "396          82       1  \n",
       "397          82       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "dataset_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset = dataset.dropna()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names.remove('MPG')\n",
    "data_cols =column_names \n",
    "data_type = (len(data_cols)-1) * ['numerical'] + ['categorical']\n",
    "data_type = dict(zip(data_cols, data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.310510</td>\n",
       "      <td>5.477707</td>\n",
       "      <td>195.318471</td>\n",
       "      <td>104.869427</td>\n",
       "      <td>2990.251592</td>\n",
       "      <td>15.559236</td>\n",
       "      <td>75.898089</td>\n",
       "      <td>1.573248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.728652</td>\n",
       "      <td>1.699788</td>\n",
       "      <td>104.331589</td>\n",
       "      <td>38.096214</td>\n",
       "      <td>843.898596</td>\n",
       "      <td>2.789230</td>\n",
       "      <td>3.675642</td>\n",
       "      <td>0.800988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1649.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>2256.500000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>2822.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.950000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>265.750000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>3608.000000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MPG   Cylinders  Displacement  Horsepower       Weight  \\\n",
       "count  314.000000  314.000000    314.000000  314.000000   314.000000   \n",
       "mean    23.310510    5.477707    195.318471  104.869427  2990.251592   \n",
       "std      7.728652    1.699788    104.331589   38.096214   843.898596   \n",
       "min     10.000000    3.000000     68.000000   46.000000  1649.000000   \n",
       "25%     17.000000    4.000000    105.500000   76.250000  2256.500000   \n",
       "50%     22.000000    4.000000    151.000000   94.500000  2822.500000   \n",
       "75%     28.950000    8.000000    265.750000  128.000000  3608.000000   \n",
       "max     46.600000    8.000000    455.000000  225.000000  5140.000000   \n",
       "\n",
       "       Acceleration  Model Year      Origin  \n",
       "count    314.000000  314.000000  314.000000  \n",
       "mean      15.559236   75.898089    1.573248  \n",
       "std        2.789230    3.675642    0.800988  \n",
       "min        8.000000   70.000000    1.000000  \n",
       "25%       13.800000   73.000000    1.000000  \n",
       "50%       15.500000   76.000000    1.000000  \n",
       "75%       17.200000   79.000000    2.000000  \n",
       "max       24.800000   82.000000    3.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 8 steps, validate for 2 steps\n",
      "Epoch 1/1000\n",
      "8/8 [==============================] - ETA: 4s - loss: 2425.9497 - mean_squared_error: 2425.94 - 1s 97ms/step - loss: 974.4975 - mean_squared_error: 979.4163 - val_loss: 1149.2871 - val_mean_squared_error: 1139.5518\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 984.5889 - mean_squared_error: 984.58 - 0s 13ms/step - loss: 599.8249 - mean_squared_error: 600.2736 - val_loss: 253.6318 - val_mean_squared_error: 254.9322\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 230.1396 - mean_squared_error: 230.13 - 0s 13ms/step - loss: 203.6502 - mean_squared_error: 205.0637 - val_loss: 107.6692 - val_mean_squared_error: 107.6394\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 63.1774 - mean_squared_error: 63.17 - 0s 7ms/step - loss: 140.5527 - mean_squared_error: 141.0983 - val_loss: 186.3447 - val_mean_squared_error: 184.4336\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 114.0941 - mean_squared_error: 114.09 - 0s 6ms/step - loss: 165.0966 - mean_squared_error: 165.0311 - val_loss: 109.8325 - val_mean_squared_error: 110.1795\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 77.2823 - mean_squared_error: 77.28 - 0s 12ms/step - loss: 100.2114 - mean_squared_error: 100.2855 - val_loss: 93.5080 - val_mean_squared_error: 93.3927\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 53.7585 - mean_squared_error: 53.75 - 0s 6ms/step - loss: 91.8275 - mean_squared_error: 91.8722 - val_loss: 108.0740 - val_mean_squared_error: 107.3036\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 58.6210 - mean_squared_error: 58.62 - 0s 12ms/step - loss: 106.1188 - mean_squared_error: 106.2626 - val_loss: 92.1200 - val_mean_squared_error: 91.6776\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 50.0919 - mean_squared_error: 50.09 - 0s 12ms/step - loss: 100.8199 - mean_squared_error: 100.8664 - val_loss: 83.7869 - val_mean_squared_error: 83.5639\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 47.6042 - mean_squared_error: 47.60 - 0s 12ms/step - loss: 90.5982 - mean_squared_error: 90.6348 - val_loss: 82.9879 - val_mean_squared_error: 82.6778\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 46.8743 - mean_squared_error: 46.87 - 0s 6ms/step - loss: 88.9268 - mean_squared_error: 89.0131 - val_loss: 85.7213 - val_mean_squared_error: 85.2803\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 48.7931 - mean_squared_error: 48.79 - 0s 6ms/step - loss: 92.0468 - mean_squared_error: 92.2066 - val_loss: 87.1605 - val_mean_squared_error: 86.6637\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 50.7285 - mean_squared_error: 50.72 - 0s 6ms/step - loss: 94.6735 - mean_squared_error: 94.8917 - val_loss: 87.0042 - val_mean_squared_error: 86.4959\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 51.7789 - mean_squared_error: 51.77 - 0s 6ms/step - loss: 95.6371 - mean_squared_error: 95.8962 - val_loss: 87.4137 - val_mean_squared_error: 86.8920\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 53.2606 - mean_squared_error: 53.26 - 0s 6ms/step - loss: 96.1700 - mean_squared_error: 96.4688 - val_loss: 89.5011 - val_mean_squared_error: 88.9490\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 56.0064 - mean_squared_error: 56.00 - 0s 6ms/step - loss: 97.3098 - mean_squared_error: 97.6552 - val_loss: 93.3461 - val_mean_squared_error: 92.7506\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 60.1598 - mean_squared_error: 60.15 - 0s 8ms/step - loss: 99.3061 - mean_squared_error: 99.7048 - val_loss: 98.6036 - val_mean_squared_error: 97.9588\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 65.5230 - mean_squared_error: 65.52 - 0s 6ms/step - loss: 101.9711 - mean_squared_error: 102.4259 - val_loss: 104.8591 - val_mean_squared_error: 104.1640\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 71.7857 - mean_squared_error: 71.78 - 0s 6ms/step - loss: 105.0215 - mean_squared_error: 105.5312 - val_loss: 111.7394 - val_mean_squared_error: 110.9959\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 78.6333 - mean_squared_error: 78.63 - 0s 6ms/step - loss: 108.2235 - mean_squared_error: 108.7839 - val_loss: 118.9131 - val_mean_squared_error: 118.1250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1266fbd610c3984c0ae371f663d55ab4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 82.98786926269531</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-regression_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 10 steps, validate for 2 steps\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - ETA: 3s - loss: 258817.2969 - mean_squared_error: 258817.29 - 1s 58ms/step - loss: 92950.7855 - mean_squared_error: 94335.7266 - val_loss: 660.1186 - val_mean_squared_error: 652.9445\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 557.0396 - mean_squared_error: 557.03 - 0s 6ms/step - loss: 7162.4788 - mean_squared_error: 7071.5923 - val_loss: 12642.2383 - val_mean_squared_error: 12638.1797\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 12621.5625 - mean_squared_error: 12621.56 - 0s 6ms/step - loss: 6676.7657 - mean_squared_error: 6748.6099 - val_loss: 917.0541 - val_mean_squared_error: 920.7798\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 860.7330 - mean_squared_error: 860.73 - 0s 8ms/step - loss: 1190.6682 - mean_squared_error: 1178.1156 - val_loss: 2139.3894 - val_mean_squared_error: 2117.5208\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 1928.4686 - mean_squared_error: 1928.46 - ETA: 0s - loss: 1418.7506 - mean_squared_error: 1427.98 - 0s 10ms/step - loss: 1365.6750 - mean_squared_error: 1375.4614 - val_loss: 640.5950 - val_mean_squared_error: 636.9205\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 536.7621 - mean_squared_error: 536.76 - 0s 6ms/step - loss: 661.3762 - mean_squared_error: 659.5060 - val_loss: 819.1504 - val_mean_squared_error: 822.1732\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 760.7185 - mean_squared_error: 760.71 - 0s 5ms/step - loss: 630.2864 - mean_squared_error: 631.1022 - val_loss: 601.7683 - val_mean_squared_error: 599.5530\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 510.0239 - mean_squared_error: 510.02 - 0s 6ms/step - loss: 560.2715 - mean_squared_error: 559.7260 - val_loss: 614.4979 - val_mean_squared_error: 611.0724\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 516.8958 - mean_squared_error: 516.89 - 0s 6ms/step - loss: 534.6226 - mean_squared_error: 534.4357 - val_loss: 587.2343 - val_mean_squared_error: 586.4862\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 508.0914 - mean_squared_error: 508.09 - 0s 6ms/step - loss: 525.7402 - mean_squared_error: 525.4163 - val_loss: 573.5647 - val_mean_squared_error: 572.2179\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 492.3879 - mean_squared_error: 492.38 - 0s 5ms/step - loss: 513.2440 - mean_squared_error: 512.8730 - val_loss: 565.7401 - val_mean_squared_error: 563.8115\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 482.7743 - mean_squared_error: 482.77 - 0s 5ms/step - loss: 505.0434 - mean_squared_error: 504.7333 - val_loss: 554.7372 - val_mean_squared_error: 553.3962\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 477.2802 - mean_squared_error: 477.28 - 0s 6ms/step - loss: 496.5740 - mean_squared_error: 496.2391 - val_loss: 544.9239 - val_mean_squared_error: 543.5037\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 468.8839 - mean_squared_error: 468.88 - 0s 5ms/step - loss: 487.7440 - mean_squared_error: 487.4129 - val_loss: 535.1327 - val_mean_squared_error: 533.6263\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 460.5062 - mean_squared_error: 460.50 - 0s 5ms/step - loss: 479.0957 - mean_squared_error: 478.7770 - val_loss: 524.8940 - val_mean_squared_error: 523.5412\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 453.1646 - mean_squared_error: 453.16 - 0s 5ms/step - loss: 470.2527 - mean_squared_error: 469.9321 - val_loss: 514.6764 - val_mean_squared_error: 513.3132\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 444.8634 - mean_squared_error: 444.86 - 0s 5ms/step - loss: 461.2702 - mean_squared_error: 460.9556 - val_loss: 504.3249 - val_mean_squared_error: 502.9902\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 436.6754 - mean_squared_error: 436.67 - 0s 6ms/step - loss: 452.2401 - mean_squared_error: 451.9303 - val_loss: 493.8605 - val_mean_squared_error: 492.5818\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 428.5400 - mean_squared_error: 428.54 - 0s 6ms/step - loss: 443.1136 - mean_squared_error: 442.8068 - val_loss: 483.3581 - val_mean_squared_error: 482.1007\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 420.1594 - mean_squared_error: 420.15 - 0s 5ms/step - loss: 433.9384 - mean_squared_error: 433.6366 - val_loss: 472.7939 - val_mean_squared_error: 471.5781\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 411.8317 - mean_squared_error: 411.83 - 0s 5ms/step - loss: 424.7321 - mean_squared_error: 424.4342 - val_loss: 462.2101 - val_mean_squared_error: 461.0305\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 403.4412 - mean_squared_error: 403.44 - 0s 5ms/step - loss: 415.5015 - mean_squared_error: 415.2077 - val_loss: 451.6211 - val_mean_squared_error: 450.4759\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 395.0202 - mean_squared_error: 395.02 - 0s 5ms/step - loss: 406.2715 - mean_squared_error: 405.9820 - val_loss: 441.0415 - val_mean_squared_error: 439.9343\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 386.6095 - mean_squared_error: 386.60 - 0s 5ms/step - loss: 397.0533 - mean_squared_error: 396.7679 - val_loss: 430.4921 - val_mean_squared_error: 429.4201\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 378.1915 - mean_squared_error: 378.19 - 0s 5ms/step - loss: 387.8609 - mean_squared_error: 387.5798 - val_loss: 419.9845 - val_mean_squared_error: 418.9490\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 369.7958 - mean_squared_error: 369.79 - 0s 5ms/step - loss: 378.7080 - mean_squared_error: 378.4310 - val_loss: 409.5364 - val_mean_squared_error: 408.5367\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 361.4266 - mean_squared_error: 361.42 - 0s 5ms/step - loss: 369.6061 - mean_squared_error: 369.3334 - val_loss: 399.1597 - val_mean_squared_error: 398.1956\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 353.0959 - mean_squared_error: 353.09 - 0s 6ms/step - loss: 360.5678 - mean_squared_error: 360.2993 - val_loss: 388.8673 - val_mean_squared_error: 387.9387\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 344.8137 - mean_squared_error: 344.81 - 0s 5ms/step - loss: 351.6027 - mean_squared_error: 351.3384 - val_loss: 378.6709 - val_mean_squared_error: 377.7773\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 336.5874 - mean_squared_error: 336.58 - 0s 5ms/step - loss: 342.7208 - mean_squared_error: 342.4607 - val_loss: 368.5808 - val_mean_squared_error: 367.7219\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 328.4259 - mean_squared_error: 328.42 - 0s 5ms/step - loss: 333.9312 - mean_squared_error: 333.6754 - val_loss: 358.6090 - val_mean_squared_error: 357.7843\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 320.3391 - mean_squared_error: 320.33 - 0s 5ms/step - loss: 325.2430 - mean_squared_error: 324.9913 - val_loss: 348.7629 - val_mean_squared_error: 347.9720\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 312.3322 - mean_squared_error: 312.33 - 0s 5ms/step - loss: 316.6635 - mean_squared_error: 316.4161 - val_loss: 339.0520 - val_mean_squared_error: 338.2943\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 304.4128 - mean_squared_error: 304.41 - 0s 5ms/step - loss: 308.2002 - mean_squared_error: 307.9571 - val_loss: 329.4836 - val_mean_squared_error: 328.7587\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 296.5854 - mean_squared_error: 296.58 - 0s 6ms/step - loss: 299.8597 - mean_squared_error: 299.6208 - val_loss: 320.0665 - val_mean_squared_error: 319.3738\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 288.8599 - mean_squared_error: 288.85 - 0s 5ms/step - loss: 291.6486 - mean_squared_error: 291.4139 - val_loss: 310.8064 - val_mean_squared_error: 310.1452\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 281.2379 - mean_squared_error: 281.23 - 0s 5ms/step - loss: 283.5724 - mean_squared_error: 283.3418 - val_loss: 301.7079 - val_mean_squared_error: 301.0778\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 273.7248 - mean_squared_error: 273.72 - 0s 5ms/step - loss: 275.6358 - mean_squared_error: 275.4095 - val_loss: 292.7799 - val_mean_squared_error: 292.1801\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 266.3273 - mean_squared_error: 266.32 - 0s 5ms/step - loss: 267.8441 - mean_squared_error: 267.6219 - val_loss: 284.0243 - val_mean_squared_error: 283.4542\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 259.0481 - mean_squared_error: 259.04 - 0s 5ms/step - loss: 260.2012 - mean_squared_error: 259.9832 - val_loss: 275.4475 - val_mean_squared_error: 274.9064\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 251.8915 - mean_squared_error: 251.89 - 0s 5ms/step - loss: 252.7106 - mean_squared_error: 252.4968 - val_loss: 267.0522 - val_mean_squared_error: 266.5393\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 244.8608 - mean_squared_error: 244.86 - 0s 5ms/step - loss: 245.3764 - mean_squared_error: 245.1668 - val_loss: 258.8427 - val_mean_squared_error: 258.3575\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 237.9584 - mean_squared_error: 237.95 - 0s 5ms/step - loss: 238.2006 - mean_squared_error: 237.9951 - val_loss: 250.8219 - val_mean_squared_error: 250.3634\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 231.1886 - mean_squared_error: 231.18 - 0s 5ms/step - loss: 231.1866 - mean_squared_error: 230.9852 - val_loss: 242.9908 - val_mean_squared_error: 242.5584\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 224.5516 - mean_squared_error: 224.55 - 0s 6ms/step - loss: 224.3357 - mean_squared_error: 224.1384 - val_loss: 235.3535 - val_mean_squared_error: 234.9465\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 218.0524 - mean_squared_error: 218.05 - 0s 5ms/step - loss: 217.6505 - mean_squared_error: 217.4573 - val_loss: 227.9123 - val_mean_squared_error: 227.5298\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 211.6914 - mean_squared_error: 211.69 - 0s 5ms/step - loss: 211.1320 - mean_squared_error: 210.9429 - val_loss: 220.6648 - val_mean_squared_error: 220.3062\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 205.4691 - mean_squared_error: 205.46 - 0s 5ms/step - loss: 204.7813 - mean_squared_error: 204.5962 - val_loss: 213.6152 - val_mean_squared_error: 213.2797\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 199.3889 - mean_squared_error: 199.38 - 0s 5ms/step - loss: 198.5991 - mean_squared_error: 198.4179 - val_loss: 206.7632 - val_mean_squared_error: 206.4499\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 193.4510 - mean_squared_error: 193.45 - 0s 5ms/step - loss: 192.5857 - mean_squared_error: 192.4086 - val_loss: 200.1087 - val_mean_squared_error: 199.8169\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 187.6557 - mean_squared_error: 187.65 - 0s 6ms/step - loss: 186.7416 - mean_squared_error: 186.5685 - val_loss: 193.6515 - val_mean_squared_error: 193.3804\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 182.0041 - mean_squared_error: 182.00 - 0s 5ms/step - loss: 181.0665 - mean_squared_error: 180.8973 - val_loss: 187.3898 - val_mean_squared_error: 187.1386\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 176.4952 - mean_squared_error: 176.49 - 0s 5ms/step - loss: 175.5599 - mean_squared_error: 175.3945 - val_loss: 181.3251 - val_mean_squared_error: 181.0931\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 171.1310 - mean_squared_error: 171.13 - 0s 5ms/step - loss: 170.2208 - mean_squared_error: 170.0592 - val_loss: 175.4542 - val_mean_squared_error: 175.2405\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 165.9098 - mean_squared_error: 165.90 - 0s 5ms/step - loss: 165.0486 - mean_squared_error: 164.8908 - val_loss: 169.7766 - val_mean_squared_error: 169.5806\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 160.8322 - mean_squared_error: 160.83 - 0s 5ms/step - loss: 160.0418 - mean_squared_error: 159.8878 - val_loss: 164.2909 - val_mean_squared_error: 164.1117\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 155.8974 - mean_squared_error: 155.89 - 0s 5ms/step - loss: 155.1994 - mean_squared_error: 155.0490 - val_loss: 158.9937 - val_mean_squared_error: 158.8306\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 151.1035 - mean_squared_error: 151.10 - 0s 5ms/step - loss: 150.5189 - mean_squared_error: 150.3722 - val_loss: 153.8832 - val_mean_squared_error: 153.7355\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 146.4502 - mean_squared_error: 146.45 - 0s 5ms/step - loss: 145.9986 - mean_squared_error: 145.8556 - val_loss: 148.9578 - val_mean_squared_error: 148.8247\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 141.9377 - mean_squared_error: 141.93 - 0s 5ms/step - loss: 141.6368 - mean_squared_error: 141.4973 - val_loss: 144.2136 - val_mean_squared_error: 144.0944\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 137.5622 - mean_squared_error: 137.56 - 0s 5ms/step - loss: 137.4309 - mean_squared_error: 137.2949 - val_loss: 139.6476 - val_mean_squared_error: 139.5416\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 133.3237 - mean_squared_error: 133.32 - 0s 5ms/step - loss: 133.3783 - mean_squared_error: 133.2457 - val_loss: 135.2581 - val_mean_squared_error: 135.1645\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 129.2212 - mean_squared_error: 129.22 - 0s 6ms/step - loss: 129.4766 - mean_squared_error: 129.3474 - val_loss: 131.0397 - val_mean_squared_error: 130.9580\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 125.2506 - mean_squared_error: 125.25 - 0s 5ms/step - loss: 125.7227 - mean_squared_error: 125.5968 - val_loss: 126.9901 - val_mean_squared_error: 126.9194\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 121.4121 - mean_squared_error: 121.41 - 0s 5ms/step - loss: 122.1137 - mean_squared_error: 121.9910 - val_loss: 123.1057 - val_mean_squared_error: 123.0455\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 117.7029 - mean_squared_error: 117.70 - 0s 5ms/step - loss: 118.6462 - mean_squared_error: 118.5268 - val_loss: 119.3817 - val_mean_squared_error: 119.3313\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 114.1200 - mean_squared_error: 114.12 - 0s 5ms/step - loss: 115.3176 - mean_squared_error: 115.2013 - val_loss: 115.8139 - val_mean_squared_error: 115.7727\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 110.6619 - mean_squared_error: 110.66 - 0s 5ms/step - loss: 112.1239 - mean_squared_error: 112.0107 - val_loss: 112.4006 - val_mean_squared_error: 112.3679\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 107.3267 - mean_squared_error: 107.32 - 0s 5ms/step - loss: 109.0621 - mean_squared_error: 108.9519 - val_loss: 109.1349 - val_mean_squared_error: 109.1103\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 104.1104 - mean_squared_error: 104.11 - 0s 5ms/step - loss: 106.1283 - mean_squared_error: 106.0210 - val_loss: 106.0136 - val_mean_squared_error: 105.9963\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 101.0115 - mean_squared_error: 101.01 - 0s 5ms/step - loss: 103.3192 - mean_squared_error: 103.2147 - val_loss: 103.0326 - val_mean_squared_error: 103.0221\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 98.0276 - mean_squared_error: 98.02 - 0s 6ms/step - loss: 100.6313 - mean_squared_error: 100.5297 - val_loss: 100.1873 - val_mean_squared_error: 100.1832\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 95.1552 - mean_squared_error: 95.15 - 0s 5ms/step - loss: 98.0603 - mean_squared_error: 97.9613 - val_loss: 97.4733 - val_mean_squared_error: 97.4750\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 92.3922 - mean_squared_error: 92.39 - 0s 5ms/step - loss: 95.6029 - mean_squared_error: 95.5065 - val_loss: 94.8854 - val_mean_squared_error: 94.8923\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 89.7339 - mean_squared_error: 89.73 - 0s 5ms/step - loss: 93.2551 - mean_squared_error: 93.1613 - val_loss: 92.4199 - val_mean_squared_error: 92.4317\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 87.1796 - mean_squared_error: 87.17 - 0s 5ms/step - loss: 91.0132 - mean_squared_error: 90.9220 - val_loss: 90.0726 - val_mean_squared_error: 90.0887\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 84.7263 - mean_squared_error: 84.72 - 0s 5ms/step - loss: 88.8733 - mean_squared_error: 88.7844 - val_loss: 87.8386 - val_mean_squared_error: 87.8586\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 82.3704 - mean_squared_error: 82.37 - 0s 5ms/step - loss: 86.8320 - mean_squared_error: 86.7455 - val_loss: 85.7126 - val_mean_squared_error: 85.7360\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 80.1080 - mean_squared_error: 80.10 - 0s 5ms/step - loss: 84.8852 - mean_squared_error: 84.8009 - val_loss: 83.6913 - val_mean_squared_error: 83.7178\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 77.9380 - mean_squared_error: 77.93 - 0s 5ms/step - loss: 83.0289 - mean_squared_error: 82.9467 - val_loss: 81.7702 - val_mean_squared_error: 81.7993\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 75.8564 - mean_squared_error: 75.85 - 0s 6ms/step - loss: 81.2600 - mean_squared_error: 81.1799 - val_loss: 79.9448 - val_mean_squared_error: 79.9761\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 73.8605 - mean_squared_error: 73.86 - 0s 5ms/step - loss: 79.5743 - mean_squared_error: 79.4963 - val_loss: 78.2099 - val_mean_squared_error: 78.2433\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 71.9467 - mean_squared_error: 71.94 - 0s 5ms/step - loss: 77.9688 - mean_squared_error: 77.8927 - val_loss: 76.5632 - val_mean_squared_error: 76.5981\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 70.1134 - mean_squared_error: 70.11 - 0s 5ms/step - loss: 76.4391 - mean_squared_error: 76.3648 - val_loss: 74.9991 - val_mean_squared_error: 75.0353\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 68.3572 - mean_squared_error: 68.35 - 0s 5ms/step - loss: 74.9825 - mean_squared_error: 74.9101 - val_loss: 73.5140 - val_mean_squared_error: 73.5512\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 66.6750 - mean_squared_error: 66.67 - 0s 5ms/step - loss: 73.5952 - mean_squared_error: 73.5245 - val_loss: 72.1046 - val_mean_squared_error: 72.1424\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 65.0645 - mean_squared_error: 65.06 - 0s 5ms/step - loss: 72.2741 - mean_squared_error: 72.2050 - val_loss: 70.7660 - val_mean_squared_error: 70.8043\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 63.5225 - mean_squared_error: 63.52 - 0s 5ms/step - loss: 71.0155 - mean_squared_error: 70.9480 - val_loss: 69.4948 - val_mean_squared_error: 69.5333\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 62.0463 - mean_squared_error: 62.04 - 0s 5ms/step - loss: 69.8164 - mean_squared_error: 69.7503 - val_loss: 68.2877 - val_mean_squared_error: 68.3262\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 60.6334 - mean_squared_error: 60.63 - 0s 6ms/step - loss: 68.6742 - mean_squared_error: 68.6095 - val_loss: 67.1414 - val_mean_squared_error: 67.1796\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 59.2815 - mean_squared_error: 59.28 - 0s 5ms/step - loss: 67.5853 - mean_squared_error: 67.5220 - val_loss: 66.0516 - val_mean_squared_error: 66.0893\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 57.9876 - mean_squared_error: 57.98 - 0s 5ms/step - loss: 66.5471 - mean_squared_error: 66.4850 - val_loss: 65.0164 - val_mean_squared_error: 65.0535\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 56.7499 - mean_squared_error: 56.74 - 0s 5ms/step - loss: 65.5572 - mean_squared_error: 65.4963 - val_loss: 64.0318 - val_mean_squared_error: 64.0679\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 55.5654 - mean_squared_error: 55.56 - 0s 5ms/step - loss: 64.6122 - mean_squared_error: 64.5524 - val_loss: 63.0945 - val_mean_squared_error: 63.1296\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 54.4318 - mean_squared_error: 54.43 - 0s 5ms/step - loss: 63.7099 - mean_squared_error: 63.6512 - val_loss: 62.2022 - val_mean_squared_error: 62.2362\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 53.3470 - mean_squared_error: 53.34 - 0s 5ms/step - loss: 62.8479 - mean_squared_error: 62.7902 - val_loss: 61.3523 - val_mean_squared_error: 61.3850\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 52.3093 - mean_squared_error: 52.30 - 0s 5ms/step - loss: 62.0238 - mean_squared_error: 61.9670 - val_loss: 60.5421 - val_mean_squared_error: 60.5734\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 51.3161 - mean_squared_error: 51.31 - 0s 6ms/step - loss: 61.2353 - mean_squared_error: 61.1793 - val_loss: 59.7686 - val_mean_squared_error: 59.7984\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 50.3654 - mean_squared_error: 50.36 - 0s 5ms/step - loss: 60.4802 - mean_squared_error: 60.4250 - val_loss: 59.0297 - val_mean_squared_error: 59.0579\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 49.4552 - mean_squared_error: 49.45 - 0s 5ms/step - loss: 59.7567 - mean_squared_error: 59.7023 - val_loss: 58.3232 - val_mean_squared_error: 58.3497\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 48.5837 - mean_squared_error: 48.58 - 0s 6ms/step - loss: 59.0625 - mean_squared_error: 59.0087 - val_loss: 57.6472 - val_mean_squared_error: 57.6718\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 47.7493 - mean_squared_error: 47.74 - 0s 5ms/step - loss: 58.3960 - mean_squared_error: 58.3428 - val_loss: 56.9992 - val_mean_squared_error: 57.0219\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 46.9498 - mean_squared_error: 46.94 - 0s 5ms/step - loss: 57.7554 - mean_squared_error: 57.7027 - val_loss: 56.3780 - val_mean_squared_error: 56.3987\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 46.1839 - mean_squared_error: 46.18 - 0s 5ms/step - loss: 57.1388 - mean_squared_error: 57.0867 - val_loss: 55.7812 - val_mean_squared_error: 55.7999\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 45.4499 - mean_squared_error: 45.44 - 0s 5ms/step - loss: 56.5452 - mean_squared_error: 56.4935 - val_loss: 55.2068 - val_mean_squared_error: 55.2235\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 44.7459 - mean_squared_error: 44.74 - 0s 5ms/step - loss: 55.9725 - mean_squared_error: 55.9212 - val_loss: 54.6540 - val_mean_squared_error: 54.6686\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 44.0711 - mean_squared_error: 44.07 - 0s 5ms/step - loss: 55.4196 - mean_squared_error: 55.3686 - val_loss: 54.1219 - val_mean_squared_error: 54.1342\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 43.4240 - mean_squared_error: 43.42 - 0s 5ms/step - loss: 54.8856 - mean_squared_error: 54.8350 - val_loss: 53.6081 - val_mean_squared_error: 53.6183\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 42.8032 - mean_squared_error: 42.80 - 0s 5ms/step - loss: 54.3687 - mean_squared_error: 54.3184 - val_loss: 53.1109 - val_mean_squared_error: 53.1188\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 42.2069 - mean_squared_error: 42.20 - 0s 5ms/step - loss: 53.8678 - mean_squared_error: 53.8177 - val_loss: 52.6302 - val_mean_squared_error: 52.6359\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 41.6348 - mean_squared_error: 41.63 - 0s 5ms/step - loss: 53.3822 - mean_squared_error: 53.3323 - val_loss: 52.1645 - val_mean_squared_error: 52.1679\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 41.0850 - mean_squared_error: 41.08 - 0s 5ms/step - loss: 52.9108 - mean_squared_error: 52.8610 - val_loss: 51.7130 - val_mean_squared_error: 51.7141\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 40.5572 - mean_squared_error: 40.55 - 0s 5ms/step - loss: 52.4527 - mean_squared_error: 52.4031 - val_loss: 51.2742 - val_mean_squared_error: 51.2730\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 40.0495 - mean_squared_error: 40.04 - 0s 5ms/step - loss: 52.0069 - mean_squared_error: 51.9573 - val_loss: 50.8473 - val_mean_squared_error: 50.8438\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 39.5612 - mean_squared_error: 39.56 - 0s 5ms/step - loss: 51.5723 - mean_squared_error: 51.5228 - val_loss: 50.4325 - val_mean_squared_error: 50.4266\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 39.0921 - mean_squared_error: 39.09 - 0s 8ms/step - loss: 51.1491 - mean_squared_error: 51.0996 - val_loss: 50.0280 - val_mean_squared_error: 50.0199\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 38.6402 - mean_squared_error: 38.64 - 0s 6ms/step - loss: 50.7357 - mean_squared_error: 50.6863 - val_loss: 49.6337 - val_mean_squared_error: 49.6232\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 38.2058 - mean_squared_error: 38.20 - 0s 5ms/step - loss: 50.3321 - mean_squared_error: 50.2825 - val_loss: 49.2489 - val_mean_squared_error: 49.2361\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 37.7871 - mean_squared_error: 37.78 - 0s 6ms/step - loss: 49.9375 - mean_squared_error: 49.8879 - val_loss: 48.8728 - val_mean_squared_error: 48.8576\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 37.3842 - mean_squared_error: 37.38 - 0s 5ms/step - loss: 49.5514 - mean_squared_error: 49.5017 - val_loss: 48.5047 - val_mean_squared_error: 48.4873\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 36.9960 - mean_squared_error: 36.99 - 0s 5ms/step - loss: 49.1729 - mean_squared_error: 49.1232 - val_loss: 48.1450 - val_mean_squared_error: 48.1253\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 36.6217 - mean_squared_error: 36.62 - 0s 5ms/step - loss: 48.8025 - mean_squared_error: 48.7526 - val_loss: 47.7931 - val_mean_squared_error: 47.7711\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 36.2613 - mean_squared_error: 36.26 - 0s 5ms/step - loss: 48.4392 - mean_squared_error: 48.3892 - val_loss: 47.4481 - val_mean_squared_error: 47.4237\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 35.9137 - mean_squared_error: 35.91 - 0s 5ms/step - loss: 48.0827 - mean_squared_error: 48.0325 - val_loss: 47.1104 - val_mean_squared_error: 47.0837\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 35.5788 - mean_squared_error: 35.57 - 0s 6ms/step - loss: 47.7326 - mean_squared_error: 47.6823 - val_loss: 46.7791 - val_mean_squared_error: 46.7501\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 35.2556 - mean_squared_error: 35.25 - 0s 5ms/step - loss: 47.3889 - mean_squared_error: 47.3384 - val_loss: 46.4544 - val_mean_squared_error: 46.4232\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 34.9441 - mean_squared_error: 34.94 - 0s 5ms/step - loss: 47.0510 - mean_squared_error: 47.0003 - val_loss: 46.1357 - val_mean_squared_error: 46.1023\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 34.6437 - mean_squared_error: 34.64 - 0s 5ms/step - loss: 46.7188 - mean_squared_error: 46.6679 - val_loss: 45.8230 - val_mean_squared_error: 45.7873\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 34.3538 - mean_squared_error: 34.35 - 0s 5ms/step - loss: 46.3922 - mean_squared_error: 46.3411 - val_loss: 45.5165 - val_mean_squared_error: 45.4785\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 34.0741 - mean_squared_error: 34.07 - 0s 5ms/step - loss: 46.0710 - mean_squared_error: 46.0197 - val_loss: 45.2157 - val_mean_squared_error: 45.1755\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 33.8046 - mean_squared_error: 33.80 - 0s 5ms/step - loss: 45.7551 - mean_squared_error: 45.7037 - val_loss: 44.9209 - val_mean_squared_error: 44.8784\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 33.5451 - mean_squared_error: 33.54 - 0s 5ms/step - loss: 45.4442 - mean_squared_error: 45.3925 - val_loss: 44.6312 - val_mean_squared_error: 44.5865\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 33.2943 - mean_squared_error: 33.29 - 0s 5ms/step - loss: 45.1381 - mean_squared_error: 45.0862 - val_loss: 44.3477 - val_mean_squared_error: 44.3008\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 33.0531 - mean_squared_error: 33.05 - 0s 5ms/step - loss: 44.8369 - mean_squared_error: 44.7848 - val_loss: 44.0691 - val_mean_squared_error: 44.0200\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 32.8204 - mean_squared_error: 32.82 - 0s 5ms/step - loss: 44.5406 - mean_squared_error: 44.4882 - val_loss: 43.7965 - val_mean_squared_error: 43.7452\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 32.5965 - mean_squared_error: 32.59 - 0s 5ms/step - loss: 44.2488 - mean_squared_error: 44.1963 - val_loss: 43.5297 - val_mean_squared_error: 43.4761\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 32.3811 - mean_squared_error: 32.38 - 0s 6ms/step - loss: 43.9618 - mean_squared_error: 43.9090 - val_loss: 43.2684 - val_mean_squared_error: 43.2126\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 32.1739 - mean_squared_error: 32.17 - 0s 5ms/step - loss: 43.6796 - mean_squared_error: 43.6266 - val_loss: 43.0129 - val_mean_squared_error: 42.9550\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 31.9752 - mean_squared_error: 31.97 - 0s 5ms/step - loss: 43.4019 - mean_squared_error: 43.3488 - val_loss: 42.7629 - val_mean_squared_error: 42.7028\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 31.7841 - mean_squared_error: 31.78 - 0s 7ms/step - loss: 43.1285 - mean_squared_error: 43.0752 - val_loss: 42.5185 - val_mean_squared_error: 42.4562\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 31.6005 - mean_squared_error: 31.60 - 0s 6ms/step - loss: 42.8597 - mean_squared_error: 42.8062 - val_loss: 42.2798 - val_mean_squared_error: 42.2153\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 31.4248 - mean_squared_error: 31.42 - 0s 5ms/step - loss: 42.5955 - mean_squared_error: 42.5418 - val_loss: 42.0481 - val_mean_squared_error: 41.9814\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 31.2574 - mean_squared_error: 31.25 - 0s 5ms/step - loss: 42.3366 - mean_squared_error: 42.2827 - val_loss: 41.8222 - val_mean_squared_error: 41.7534\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 31.0971 - mean_squared_error: 31.09 - 0s 5ms/step - loss: 42.0818 - mean_squared_error: 42.0278 - val_loss: 41.6020 - val_mean_squared_error: 41.5309\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.9441 - mean_squared_error: 30.94 - 0s 5ms/step - loss: 41.8316 - mean_squared_error: 41.7774 - val_loss: 41.3877 - val_mean_squared_error: 41.3145\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.7984 - mean_squared_error: 30.79 - 0s 5ms/step - loss: 41.5860 - mean_squared_error: 41.5317 - val_loss: 41.1805 - val_mean_squared_error: 41.1050\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.6604 - mean_squared_error: 30.66 - 0s 5ms/step - loss: 41.3454 - mean_squared_error: 41.2909 - val_loss: 40.9802 - val_mean_squared_error: 40.9025\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.5301 - mean_squared_error: 30.53 - 0s 6ms/step - loss: 41.1100 - mean_squared_error: 41.0555 - val_loss: 40.7864 - val_mean_squared_error: 40.7065\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.4069 - mean_squared_error: 30.40 - 0s 6ms/step - loss: 40.8793 - mean_squared_error: 40.8247 - val_loss: 40.5994 - val_mean_squared_error: 40.5173\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.2911 - mean_squared_error: 30.29 - 0s 6ms/step - loss: 40.6534 - mean_squared_error: 40.5987 - val_loss: 40.4197 - val_mean_squared_error: 40.3354\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.1832 - mean_squared_error: 30.18 - 0s 5ms/step - loss: 40.4330 - mean_squared_error: 40.3782 - val_loss: 40.2470 - val_mean_squared_error: 40.1604\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.0823 - mean_squared_error: 30.08 - 0s 6ms/step - loss: 40.2173 - mean_squared_error: 40.1625 - val_loss: 40.0813 - val_mean_squared_error: 39.9925\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.9886 - mean_squared_error: 29.98 - 0s 5ms/step - loss: 40.0067 - mean_squared_error: 39.9520 - val_loss: 39.9233 - val_mean_squared_error: 39.8321\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.9026 - mean_squared_error: 29.90 - 0s 5ms/step - loss: 39.8018 - mean_squared_error: 39.7471 - val_loss: 39.7742 - val_mean_squared_error: 39.6808\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.8251 - mean_squared_error: 29.82 - 0s 5ms/step - loss: 39.6027 - mean_squared_error: 39.5480 - val_loss: 39.6323 - val_mean_squared_error: 39.5366\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.7548 - mean_squared_error: 29.75 - 0s 5ms/step - loss: 39.4088 - mean_squared_error: 39.3542 - val_loss: 39.4985 - val_mean_squared_error: 39.4005\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.6920 - mean_squared_error: 29.69 - 0s 5ms/step - loss: 39.2208 - mean_squared_error: 39.1662 - val_loss: 39.3735 - val_mean_squared_error: 39.2731\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.6375 - mean_squared_error: 29.63 - 0s 6ms/step - loss: 39.0385 - mean_squared_error: 38.9840 - val_loss: 39.2569 - val_mean_squared_error: 39.1541\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5908 - mean_squared_error: 29.59 - 0s 5ms/step - loss: 38.8621 - mean_squared_error: 38.8077 - val_loss: 39.1487 - val_mean_squared_error: 39.0436\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5522 - mean_squared_error: 29.55 - 0s 5ms/step - loss: 38.6920 - mean_squared_error: 38.6377 - val_loss: 39.0504 - val_mean_squared_error: 38.9429\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5222 - mean_squared_error: 29.52 - 0s 6ms/step - loss: 38.5282 - mean_squared_error: 38.4741 - val_loss: 38.9608 - val_mean_squared_error: 38.8508\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5006 - mean_squared_error: 29.50 - 0s 6ms/step - loss: 38.3710 - mean_squared_error: 38.3171 - val_loss: 38.8813 - val_mean_squared_error: 38.7689\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.4875 - mean_squared_error: 29.48 - 0s 6ms/step - loss: 38.2204 - mean_squared_error: 38.1667 - val_loss: 38.8118 - val_mean_squared_error: 38.6969\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.4834 - mean_squared_error: 29.48 - 0s 6ms/step - loss: 38.0765 - mean_squared_error: 38.0231 - val_loss: 38.7511 - val_mean_squared_error: 38.6337\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.4875 - mean_squared_error: 29.48 - 0s 5ms/step - loss: 37.9393 - mean_squared_error: 37.8861 - val_loss: 38.7010 - val_mean_squared_error: 38.5811\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5008 - mean_squared_error: 29.50 - 0s 7ms/step - loss: 37.8093 - mean_squared_error: 37.7565 - val_loss: 38.6610 - val_mean_squared_error: 38.5386\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5230 - mean_squared_error: 29.52 - 0s 5ms/step - loss: 37.6866 - mean_squared_error: 37.6340 - val_loss: 38.6316 - val_mean_squared_error: 38.5066\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5547 - mean_squared_error: 29.55 - 0s 5ms/step - loss: 37.5715 - mean_squared_error: 37.5193 - val_loss: 38.6138 - val_mean_squared_error: 38.4862\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.5959 - mean_squared_error: 29.59 - 0s 5ms/step - loss: 37.4641 - mean_squared_error: 37.4123 - val_loss: 38.6058 - val_mean_squared_error: 38.4755\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.6464 - mean_squared_error: 29.64 - 0s 5ms/step - loss: 37.3646 - mean_squared_error: 37.3131 - val_loss: 38.6098 - val_mean_squared_error: 38.4769\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.7071 - mean_squared_error: 29.70 - 0s 5ms/step - loss: 37.2733 - mean_squared_error: 37.2222 - val_loss: 38.6248 - val_mean_squared_error: 38.4892\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.7772 - mean_squared_error: 29.77 - 0s 5ms/step - loss: 37.1902 - mean_squared_error: 37.1396 - val_loss: 38.6509 - val_mean_squared_error: 38.5127\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.8574 - mean_squared_error: 29.85 - 0s 6ms/step - loss: 37.1162 - mean_squared_error: 37.0660 - val_loss: 38.6896 - val_mean_squared_error: 38.5485\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 29.9482 - mean_squared_error: 29.94 - 0s 8ms/step - loss: 37.0508 - mean_squared_error: 37.0011 - val_loss: 38.7391 - val_mean_squared_error: 38.5953\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.0486 - mean_squared_error: 30.04 - 0s 7ms/step - loss: 36.9939 - mean_squared_error: 36.9447 - val_loss: 38.7995 - val_mean_squared_error: 38.6529\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.1585 - mean_squared_error: 30.15 - 0s 7ms/step - loss: 36.9464 - mean_squared_error: 36.8978 - val_loss: 38.8723 - val_mean_squared_error: 38.7228\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.2791 - mean_squared_error: 30.27 - 0s 7ms/step - loss: 36.9087 - mean_squared_error: 36.8605 - val_loss: 38.9567 - val_mean_squared_error: 38.8045\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.4100 - mean_squared_error: 30.41 - 0s 6ms/step - loss: 36.8807 - mean_squared_error: 36.8331 - val_loss: 39.0531 - val_mean_squared_error: 38.8980\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 30.5511 - mean_squared_error: 30.55 - 0s 7ms/step - loss: 36.8625 - mean_squared_error: 36.8154 - val_loss: 39.1605 - val_mean_squared_error: 39.0024\n",
      "3/3 [==============================] - ETA: 0s - loss: 25.1846 - mean_squared_error: 25.18 - 0s 33ms/step - loss: 42.9568 - mean_squared_error: 38.2187\n",
      "Accuracy: [42.95684305826823, 38.21874]\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "regressor = ak.StructuredDataRegressor(max_trials=1, column_names=data_cols, column_types=data_type)\n",
    "regressor.fit(x=train_dataset.drop(columns=['MPG']), y=train_dataset['MPG'])\n",
    "# Evaluate the accuracy of the found model.\n",
    "print('Accuracy: {accuracy}'.format(\n",
    "    accuracy=regressor.evaluate(x=test_dataset.drop(columns=['MPG']), y=test_dataset['MPG'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-43608d0a98b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    281\u001b[0m                      \u001b[0mrankdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrankdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                      \u001b[0mexpand_nested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpand_nested\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                      dpi=dpi)\n\u001b[0m\u001b[0;32m    284\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'IPython.core.magics.namespace'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[1;31m# We don't raise an exception here in order to avoid crashing notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mcheck_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\python36\\lib\\site-packages\\pydot_ng\\__init__.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1823\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1825\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1827\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "model = regressor.export_model()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot_ng as pydot\n",
    "print (pydot.find_graphviz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pydotplus.find_graphviz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model  #\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep +'D:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,to_file='model1.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot_ng as pydot\n",
    "print (pydot.find_graphviz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
